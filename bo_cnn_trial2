#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Apr 16 19:19:51 2022

@author: zixiao
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Apr 16 15:32:01 2022

@author: zixiao
"""
from bayes_opt import BayesianOptimization
import tensorflow as tf
from tensorflow.keras import datasets, layers, models, callbacks
from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl
import pandas as pd
pd.set_option("display.max_columns", None)
import matplotlib.pyplot as plt


from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import make_scorer, accuracy_score
from keras.wrappers.scikit_learn import KerasClassifier

import time


import warnings
warnings.filterwarnings('ignore')
# Make scorer accuracy
score_acc = make_scorer(accuracy_score)

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

def bo_tune_cnn(epochs,batch_size,conv1_ker,conv2_ker,conv3_ker,conv1_filter,conv2_filter,conv3_filter,
                pool1_ker,pool2_ker,pool3_ker,dense1_neuron,dense2_neuron,dropout_rate,learning_rate):

    

    model = models.Sequential()
    model.add(layers.Conv2D(int(conv1_filter), int(conv1_ker), activation='relu', padding="same", input_shape=(32, 32, 3)))
    model.add(layers.MaxPooling2D(int(pool1_ker)))
    model.add(layers.Conv2D(int(conv2_filter), int(conv2_ker), activation='relu', padding="same"))
    model.add(layers.MaxPooling2D(int(pool2_ker)))
    model.add(layers.Conv2D(int(conv3_filter), int(conv3_ker), activation='relu', padding="same"))
    model.add(layers.MaxPooling2D(int(pool3_ker)))
    model.add(layers.Flatten())
    model.add(layers.Dense(int(dense1_neuron), activation='relu'))
    model.add(layers.Dropout(dropout_rate))
    model.add(layers.Dense(int(dense2_neuron), activation='relu'))
    model.add(layers.Dense(10))
    
    model.compile(optimizer = 'adam',
                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])

    
    es = callbacks.EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=5)


    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])

    history = model.fit(train_images, train_labels, epochs=int(epochs), batch_size = int(batch_size), validation_split = 0.1, callbacks=[es])
    
    return history.history['accuracy'][-1]

# Set hyperparameter space
hyperspace_cnn = {

    'conv1_ker': (2, 10),
    'conv2_ker': (2, 10),
    'conv3_ker': (2, 10),
    'conv1_filter': (32, 50),
    'conv2_filter': (32, 50),
    'conv3_filter': (32, 50),
    'pool1_ker': (2, 4),
    'pool2_ker': (2, 4),
    'pool3_ker': (2, 4),
    'dense1_neuron': (32, 50),
    'dense2_neuron': (32, 50),
    'dropout_rate':(0, 0.5),
    'learning_rate':(0.1, 1),
    'batch_size':(20, 300),
    'epochs':(10, 20),
 }

# Run Bayesian Optimization
cnn_bo = BayesianOptimization(bo_tune_cnn, hyperspace_cnn, random_state=123)
cnn_bo.maximize(init_points=5, n_iter=4)