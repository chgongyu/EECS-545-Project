{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4I1fM9XEn7W"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "==================================================================\n",
        "Tuning the hyperparameters of a random forest model with hyperband\n",
        "==================================================================\n",
        "\"\"\"\n",
        "from scipy.stats import randint as sp_randint\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.model_selection._search import BaseSearchCV, ParameterSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0eJKgN6EsVt"
      },
      "outputs": [],
      "source": [
        "\n",
        "__all__ = ['HyperbandSearchCV']\n",
        "\n",
        "\n",
        "class HyperbandSearchCV(BaseSearchCV):\n",
        "    \"\"\"Hyperband search on hyper parameters.\n",
        "\n",
        "    HyperbandSearchCV implements a ``fit`` and a ``score`` method.\n",
        "    It also implements ``predict``, ``predict_proba``, ``decision_function``,\n",
        "    ``transform`` and ``inverse_transform`` if they are implemented in the\n",
        "    estimator used.\n",
        "\n",
        "    The parameters of the estimator used to apply these methods are optimized\n",
        "    by cross-validated search over parameter settings using the hyperband\n",
        "    algorithm [1]_ .\n",
        "\n",
        "    If all parameters are presented as a list,\n",
        "    sampling without replacement is performed. If at least one parameter\n",
        "    is given as a distribution, sampling with replacement is used.\n",
        "    It is highly recommended to use continuous distributions for continuous\n",
        "    parameters.\n",
        "\n",
        "    Read more in the scikit-learn `User Guide\n",
        "    <http://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-search>`_.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : estimator object.\n",
        "        A object of that type is instantiated for each grid point.\n",
        "        This is assumed to implement the scikit-learn estimator interface.\n",
        "        Either estimator needs to provide a ``score`` function,\n",
        "        or ``scoring`` must be passed.\n",
        "\n",
        "    param_distributions : dict\n",
        "        Dictionary with parameters names (string) as keys and distributions\n",
        "        or lists of parameters to try. Distributions must provide a ``rvs``\n",
        "        method for sampling (such as those from scipy.stats.distributions).\n",
        "        If a list is given, it is sampled uniformly.\n",
        "\n",
        "    resource_param : str, default='n_estimators'\n",
        "        The name of the cost parameter for the estimator ``estimator``\n",
        "        to be fitted. Typically, this is the number of decision trees\n",
        "        ``n_estimators`` in an ensemble or the number of iterations\n",
        "        for estimators trained with stochastic gradient descent.\n",
        "\n",
        "    eta : float, default=3\n",
        "        The inverse of the proportion of configurations that are discarded\n",
        "        in each round of hyperband.\n",
        "\n",
        "    min_iter : int, default=1\n",
        "        The minimum amount of resource that should be allocated to the cost\n",
        "        parameter ``resource_param`` for a single configuration of the\n",
        "        hyperparameters.\n",
        "\n",
        "    max_iter : int, default=81\n",
        "        The maximum amount of resource that can be allocated to the cost\n",
        "        parameter ``resource_param`` for a single configuration of the\n",
        "        hyperparameters.\n",
        "\n",
        "    skip_last : int, default=0\n",
        "        The number of last rounds to skip. For example, this can be used\n",
        "        to skip the last round of hyperband, which is standard randomized\n",
        "        search. It can also be used to inspect intermediate results,\n",
        "        although warm-starting HyperbandSearchCV is not supported.\n",
        "\n",
        "    scoring : string, callable, list/tuple, dict or None, default: None\n",
        "        A single string (see :ref:`scoring_parameter`) or a callable\n",
        "        (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
        "\n",
        "        For evaluating multiple metrics, either give a list of (unique) strings\n",
        "        or a dict with names as keys and callables as values.\n",
        "\n",
        "        NOTE that when using custom scorers, each scorer should return a single\n",
        "        value. Metric functions returning a list/array of values can be wrapped\n",
        "        into multiple scorers that return one value each.\n",
        "\n",
        "        See :ref:`multimetric_grid_search` for an example.\n",
        "\n",
        "        If None, the estimator's default scorer (if available) is used.\n",
        "\n",
        "    n_jobs : int, default=1\n",
        "        Number of jobs to run in parallel.\n",
        "\n",
        "    pre_dispatch : int, or string, optional\n",
        "        Controls the number of jobs that get dispatched during parallel\n",
        "        execution. Reducing this number can be useful to avoid an\n",
        "        explosion of memory consumption when more jobs get dispatched\n",
        "        than CPUs can process. This parameter can be:\n",
        "\n",
        "            - None, in which case all the jobs are immediately\n",
        "              created and spawned. Use this for lightweight and\n",
        "              fast-running jobs, to avoid delays due to on-demand\n",
        "              spawning of the jobs\n",
        "\n",
        "            - An int, giving the exact number of total jobs that are\n",
        "              spawned\n",
        "\n",
        "            - A string, giving an expression as a function of n_jobs,\n",
        "              as in '2*n_jobs'\n",
        "\n",
        "    iid : boolean, default=True\n",
        "        If True, the data is assumed to be identically distributed across\n",
        "        the folds, and the loss minimized is the total loss per sample,\n",
        "        and not the mean loss across the folds.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 3-fold cross validation,\n",
        "          - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
        "          - An object to be used as a cross-validation generator.\n",
        "          - An iterable yielding train, test splits.\n",
        "\n",
        "        For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
        "        either binary or multiclass, :class:`sklearn.model_selection.StratifiedKFold`\n",
        "        is used. In all other cases, :class:`sklearn.model_selection.KFold` is used.\n",
        "\n",
        "        Refer `User Guide <http://scikit-learn.org/stable/modules/cross_validation.html>`_\n",
        "        for the various cross-validation strategies that can be used here.\n",
        "\n",
        "    refit : boolean, or string default=True\n",
        "        Refit an estimator using the best found parameters on the whole\n",
        "        dataset.\n",
        "\n",
        "        For multiple metric evaluation, this needs to be a string denoting the\n",
        "        scorer that would be used to find the best parameters for refitting\n",
        "        the estimator at the end.\n",
        "\n",
        "        The refitted estimator is made available at the ``best_estimator_``\n",
        "        attribute and permits using ``predict`` directly on this\n",
        "        ``HyperbandSearchCV`` instance.\n",
        "\n",
        "        Also for multiple metric evaluation, the attributes ``best_index_``,\n",
        "        ``best_score_`` and ``best_parameters_`` will only be available if\n",
        "        ``refit`` is set and all of them will be determined w.r.t this specific\n",
        "        scorer.\n",
        "\n",
        "        See ``scoring`` parameter to know more about multiple metric\n",
        "        evaluation.\n",
        "\n",
        "    verbose : integer\n",
        "        Controls the verbosity: the higher, the more messages.\n",
        "\n",
        "    random_state : int, RandomState instance or None, optional, default=None\n",
        "        Pseudo random number generator state used for random uniform sampling\n",
        "        from lists of possible values instead of scipy.stats distributions.\n",
        "        If int, random_state is the seed used by the random number generator;\n",
        "        If RandomState instance, random_state is the random number generator;\n",
        "        If None, the random number generator is the RandomState instance used\n",
        "        by `np.random`.\n",
        "\n",
        "    error_score : 'raise' (default) or numeric\n",
        "        Value to assign to the score if an error occurs in estimator fitting.\n",
        "        If set to 'raise', the error is raised. If a numeric value is given,\n",
        "        FitFailedWarning is raised. This parameter does not affect the refit\n",
        "        step, which will always raise the error.\n",
        "\n",
        "    return_train_score : boolean, optional, default=False\n",
        "        If ``False``, the ``cv_results_`` attribute will not include training\n",
        "        scores.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    cv_results_ : dict of numpy (masked) ndarrays\n",
        "        A dict with keys as column headers and values as columns, that can be\n",
        "        imported into a pandas ``DataFrame``.\n",
        "\n",
        "        For instance the below given table\n",
        "\n",
        "        +------------+-----------+------------+-----------------+---+---------+\n",
        "        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
        "        +============+===========+============+=================+===+=========+\n",
        "        |  'poly'    |     --    |      2     |        0.8      |...|    2    |\n",
        "        +------------+-----------+------------+-----------------+---+---------+\n",
        "        |  'poly'    |     --    |      3     |        0.7      |...|    4    |\n",
        "        +------------+-----------+------------+-----------------+---+---------+\n",
        "        |  'rbf'     |     0.1   |     --     |        0.8      |...|    3    |\n",
        "        +------------+-----------+------------+-----------------+---+---------+\n",
        "        |  'rbf'     |     0.2   |     --     |        0.9      |...|    1    |\n",
        "        +------------+-----------+------------+-----------------+---+---------+\n",
        "\n",
        "        will be represented by a ``cv_results_`` dict of::\n",
        "\n",
        "            {\n",
        "            'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
        "                                         mask = [False False False False]...)\n",
        "            'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
        "                                        mask = [ True  True False False]...),\n",
        "            'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
        "                                         mask = [False False  True  True]...),\n",
        "            'split0_test_score'  : [0.8, 0.7, 0.8, 0.9],\n",
        "            'split1_test_score'  : [0.82, 0.5, 0.7, 0.78],\n",
        "            'mean_test_score'    : [0.81, 0.60, 0.75, 0.82],\n",
        "            'std_test_score'     : [0.02, 0.01, 0.03, 0.03],\n",
        "            'rank_test_score'    : [2, 4, 3, 1],\n",
        "            'split0_train_score' : [0.8, 0.9, 0.7],\n",
        "            'split1_train_score' : [0.82, 0.5, 0.7],\n",
        "            'mean_train_score'   : [0.81, 0.7, 0.7],\n",
        "            'std_train_score'    : [0.03, 0.03, 0.04],\n",
        "            'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
        "            'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
        "            'mean_score_time'    : [0.007, 0.06, 0.04, 0.04],\n",
        "            'std_score_time'     : [0.001, 0.002, 0.003, 0.005],\n",
        "            'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
        "            }\n",
        "\n",
        "        NOTE\n",
        "\n",
        "        The key ``'params'`` is used to store a list of parameter\n",
        "        settings dicts for all the parameter candidates.\n",
        "\n",
        "        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
        "        ``std_score_time`` are all in seconds.\n",
        "\n",
        "        For multi-metric evaluation, the scores for all the scorers are\n",
        "        available in the ``cv_results_`` dict at the keys ending with that\n",
        "        scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
        "        above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
        "\n",
        "    best_estimator_ : estimator or dict\n",
        "        Estimator that was chosen by the search, i.e. estimator\n",
        "        which gave highest score (or smallest loss if specified)\n",
        "        on the left out data. Not available if ``refit=False``.\n",
        "\n",
        "        For multi-metric evaluation, this attribute is present only if\n",
        "        ``refit`` is specified.\n",
        "\n",
        "        See ``refit`` parameter for more information on allowed values.\n",
        "\n",
        "    best_score_ : float\n",
        "        Mean cross-validated score of the best_estimator.\n",
        "\n",
        "        For multi-metric evaluation, this is not available if ``refit`` is\n",
        "        ``False``. See ``refit`` parameter for more information.\n",
        "\n",
        "    best_params_ : dict\n",
        "        Parameter setting that gave the best results on the hold out data.\n",
        "\n",
        "        For multi-metric evaluation, this is not available if ``refit`` is\n",
        "        ``False``. See ``refit`` parameter for more information.\n",
        "\n",
        "    best_index_ : int\n",
        "        The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
        "        candidate parameter setting.\n",
        "\n",
        "        The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
        "        the parameter setting for the best model, that gives the highest\n",
        "        mean score (``search.best_score_``).\n",
        "\n",
        "        For multi-metric evaluation, this is not available if ``refit`` is\n",
        "        ``False``. See ``refit`` parameter for more information.\n",
        "\n",
        "    scorer_ : function or a dict\n",
        "        Scorer function used on the held out data to choose the best\n",
        "        parameters for the model.\n",
        "\n",
        "        For multi-metric evaluation, this attribute holds the validated\n",
        "        ``scoring`` dict which maps the scorer key to the scorer callable.\n",
        "\n",
        "    n_splits_ : int\n",
        "        The number of cross-validation splits (folds/iterations).\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "\n",
        "    .. [1] Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A. and Talwalkar, A.,\n",
        "           2017. Hyperband: A novel bandit-based approach to hyperparameter\n",
        "           optimization. The Journal of Machine Learning Research, 18(1),\n",
        "           pp.6765-6816.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The parameters selected are those that maximize the score of the held-out\n",
        "    data, according to the scoring parameter.\n",
        "\n",
        "    If `n_jobs` was set to a value higher than one, the data is copied for each\n",
        "    parameter setting (and not `n_jobs` times). This is done for efficiency\n",
        "    reasons if individual jobs take very little time, but may raise errors if\n",
        "    the dataset is large and not enough memory is available.  A workaround in\n",
        "    this case is to set `pre_dispatch`. Then, the memory is copied only\n",
        "    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
        "    n_jobs`.\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    :class:`sklearn.model_selection.GridSearchCV`:\n",
        "        Does exhaustive search over a grid of parameters.\n",
        "\n",
        "    :class:`sklearn.model_selection.ParameterSampler`:\n",
        "        A generator over parameter settings, constructed from\n",
        "        param_distributions.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, estimator, param_distributions,\n",
        "                 resource_param='n_estimators', eta=3, min_iter=1,\n",
        "                 max_iter=81, skip_last=0, scoring=None, n_jobs=1,\n",
        "                 refit=True, cv=None,\n",
        "                 verbose=0, pre_dispatch='2*n_jobs', random_state=None,\n",
        "                 error_score='raise', return_train_score=False):\n",
        "        self.param_distributions = param_distributions\n",
        "        self.resource_param = resource_param\n",
        "        self.eta = eta\n",
        "        self.min_iter = min_iter\n",
        "        self.max_iter = max_iter\n",
        "        self.skip_last = skip_last\n",
        "        self.random_state = random_state\n",
        "\n",
        "        super(HyperbandSearchCV, self).__init__(\n",
        "            estimator=estimator, scoring=scoring, n_jobs=n_jobs,\n",
        "            refit=refit, cv=cv, verbose=verbose,\n",
        "            pre_dispatch=pre_dispatch, error_score=error_score,\n",
        "            return_train_score=return_train_score)\n",
        "\n",
        "    def _run_search(self, evaluate_candidates):\n",
        "        self._validate_input()\n",
        "\n",
        "        s_max = int(np.floor(np.log(self.max_iter / self.min_iter) / np.log(self.eta)))\n",
        "        B = (s_max + 1) * self.max_iter\n",
        "\n",
        "        refit_metric = self.refit if self.multimetric_ else 'score'\n",
        "        random_state = check_random_state(self.random_state)\n",
        "\n",
        "        if self.skip_last > s_max:\n",
        "            raise ValueError('skip_last is higher than the total number of rounds')\n",
        "\n",
        "        for round_index, s in enumerate(reversed(range(s_max + 1))):\n",
        "            n = int(np.ceil(int(B / self.max_iter / (s + 1)) * np.power(self.eta, s)))\n",
        "\n",
        "            # initial number of iterations per config\n",
        "            r = self.max_iter / np.power(self.eta, s)\n",
        "            configurations = list(ParameterSampler(param_distributions=self.param_distributions,\n",
        "                                                   n_iter=n,\n",
        "                                                   random_state=random_state))\n",
        "\n",
        "            if self.verbose > 0:\n",
        "                print('Starting bracket {0} (out of {1}) of hyperband'\n",
        "                      .format(round_index + 1, s_max + 1))\n",
        "\n",
        "            for i in range((s + 1) - self.skip_last):\n",
        "\n",
        "                n_configs = np.floor(n / np.power(self.eta, i))  # n_i\n",
        "                n_iterations = int(r * np.power(self.eta, i))  # r_i\n",
        "                n_to_keep = int(np.floor(n_configs / self.eta))\n",
        "\n",
        "                if self.verbose > 0:\n",
        "                    msg = ('Starting successive halving iteration {0} out of'\n",
        "                           ' {1}. Fitting {2} configurations, with'\n",
        "                           ' resource_param {3} set to {4}')\n",
        "\n",
        "                    if n_to_keep > 0:\n",
        "                        msg += ', and keeping the best {5} configurations.'\n",
        "\n",
        "                    msg = msg.format(i + 1, s + 1, len(configurations),\n",
        "                                     self.resource_param, n_iterations,\n",
        "                                     n_to_keep)\n",
        "                    print(msg)\n",
        "\n",
        "                # Set the cost parameter for every configuration\n",
        "                parameters = copy.deepcopy(configurations)\n",
        "                for configuration in parameters:\n",
        "                    configuration[self.resource_param] = n_iterations\n",
        "\n",
        "                results = evaluate_candidates(parameters)\n",
        "\n",
        "                if n_to_keep > 0:\n",
        "                    top_configurations = [x for _, x in sorted(zip(results['rank_test_%s' % refit_metric],\n",
        "                                                                   results['params']),\n",
        "                                                               key=lambda x: x[0])]\n",
        "\n",
        "                    configurations = top_configurations[:n_to_keep]\n",
        "\n",
        "            if self.skip_last > 0:\n",
        "                print('Skipping the last {0} successive halving iterations'\n",
        "                      .format(self.skip_last))\n",
        "\n",
        "    def fit(self, X, y=None, groups=None, **fit_params):\n",
        "        \"\"\"Run fit with all sets of parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            Training vector, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "\n",
        "        y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n",
        "            Target relative to X for classification or regression;\n",
        "            None for unsupervised learning.\n",
        "\n",
        "        groups : array-like, with shape (n_samples,), optional\n",
        "            Group labels for the samples used while splitting the dataset into\n",
        "            train/test set.\n",
        "\n",
        "        **fit_params : dict of string -> object\n",
        "            Parameters passed to the ``fit`` method of the estimator\n",
        "        \"\"\"\n",
        "        super().fit(X, y, groups, **fit_params)\n",
        "\n",
        "        s_max = int(np.floor(np.log(self.max_iter / self.min_iter) / np.log(self.eta)))\n",
        "        B = (s_max + 1) * self.max_iter\n",
        "\n",
        "        brackets = []\n",
        "        for round_index, s in enumerate(reversed(range(s_max + 1))):\n",
        "            n = int(np.ceil(int(B / self.max_iter / (s + 1)) * np.power(self.eta, s)))\n",
        "            n_configs = int(sum([np.floor(n / np.power(self.eta, i))\n",
        "                                 for i in range((s + 1) - self.skip_last)]))\n",
        "            bracket = (round_index + 1) * np.ones(n_configs)\n",
        "            brackets.append(bracket)\n",
        "\n",
        "        self.cv_results_['hyperband_bracket'] = np.hstack(brackets)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def _validate_input(self):\n",
        "        if not isinstance(self.min_iter, int) or self.min_iter <= 0:\n",
        "            raise ValueError('min_iter should be a positive integer, got %s' %\n",
        "                             self.min_iter)\n",
        "\n",
        "        if not isinstance(self.max_iter, int) or self.max_iter <= 0:\n",
        "            raise ValueError('max_iter should be a positive integer, got %s' %\n",
        "                             self.max_iter)\n",
        "\n",
        "        if self.max_iter < self.min_iter:\n",
        "            raise ValueError('max_iter should be bigger than min_iter, got'\n",
        "                             'max_iter=%d and min_iter=%d' % (self.max_iter,\n",
        "                                                              self.min_iter))\n",
        "\n",
        "        if not isinstance(self.skip_last, int) or self.skip_last < 0:\n",
        "            raise ValueError('skip_last should be an integer, got %s' %\n",
        "                             self.skip_last)\n",
        "\n",
        "        if not isinstance(self.eta, int) or not self.eta > 1:\n",
        "            raise ValueError('eta should be a positive integer, got %s' %\n",
        "                             self.eta)\n",
        "\n",
        "        if self.resource_param not in self.estimator.get_params().keys():\n",
        "            raise ValueError('resource_param is set to %s, but base_estimator %s '\n",
        "                             'does not have a parameter with that name' %\n",
        "                             (self.resource_param,\n",
        "                              self.estimator.__class__.__name__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VnLu_uzLE_43",
        "outputId": "02e7d615-514b-4daf-e95f-b80f8c67c105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: scikit-learn 0.23.2\n",
            "Uninstalling scikit-learn-0.23.2:\n",
            "  Successfully uninstalled scikit-learn-0.23.2\n",
            "Collecting scikit-learn==0.23.2\n",
            "  Using cached scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.23.2'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip install scikit-learn==0.23.2\n",
        "import sklearn\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rhg8-BAOmxr",
        "outputId": "e0b01716-3532-48ba-af80-866efb7295b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "# run block of code and catch warnings\n",
        "with warnings.catch_warnings():\n",
        "\t# ignore all caught warnings\n",
        "\twarnings.filterwarnings(\"ignore\")\n",
        "\t# execute code that will generate warnings\n",
        "\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj2i_oONP1Db",
        "outputId": "9b3347cd-bb23-4251-fbe0-a4ba7bd9be84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1J_PriDjeXBMe5ZgB5xWSbk3VidGot_gP/545\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/My Drive/545'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0FQclXqP_Lb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import xgboost as xgb\n",
        "from scipy.stats import uniform\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg8J71lyP5Y9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r'Churn_Modelling.csv')\n",
        "#Getting the independent features\n",
        "X = df.iloc[:,3:-1]\n",
        "#Getting the dependent feature\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "#Dummy variable for 'Geography' column\n",
        "geography = pd.get_dummies(X['Geography'], drop_first = True)\n",
        "#Dummy variable for 'Gender' column\n",
        "gender = pd.get_dummies(X['Gender'], drop_first = True)\n",
        "\n",
        "#Dropping the original 'Geography' and 'Gender' columns\n",
        "X = X.drop(['Geography','Gender'], axis = 1)\n",
        "\n",
        "#Adding the dummy columns to the dataset\n",
        "X = pd.concat([X,geography,gender], axis = 1)\n",
        "X.head()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
        "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
        "dtest = xgb.DMatrix(X_test, label = y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiGbIxw4eWJp"
      },
      "outputs": [],
      "source": [
        "global_parms = {\"booster\"         : \"gbtree\", \n",
        "                \"missing\"         : None,\n",
        "                \"n_estimators\"    : 100, \n",
        "                \"n_jobs\"          : 1, \n",
        "                \"objective\"       : 'binary:logistic', \n",
        "                \"random_state\"    : 545, \n",
        "                \"scale_pos_weight\": 1, \n",
        "                \"verbosity\"       : 1,\n",
        "                \"eval_metric\"     : 'logloss'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYActmy7gCvc"
      },
      "outputs": [],
      "source": [
        "tune_params = {\"base_score\"       : uniform(0.1,0.8),\n",
        "               \"colsample_bylevel\": uniform(0.1,0.9),\n",
        "               \"colsample_bynode\" : uniform(0.1,0.9),\n",
        "               \"colsample_bytree\" : uniform(0.1,0.9),\n",
        "               \"learning_rate\"    : uniform(0.1,0.9),\n",
        "               \"max_delta_step\"   : list(range(0, 10, 1)),\n",
        "               \"max_depth\"        : list(range(1, 20, 2)),\n",
        "               \"min_child_weight\" : uniform(1, 19),\n",
        "               \"gamma\"            : uniform(0.1,9.9),\n",
        "               \"subsample\"        : uniform(0.1,0.9),\n",
        "               \"reg_lambda\"       : uniform(1, 8),\n",
        "               \"reg_alpha\"        : uniform(1, 8) \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEVYqovVEvhg"
      },
      "outputs": [],
      "source": [
        "def tune_xgb_hb(params, X_train, y_train, random_state=545):\n",
        "  '''\n",
        "    Using Random Search to tune the parameters of XGBoost. \n",
        "    Task: Binary Search\n",
        "    Output: logloss, best_params\n",
        "  '''\n",
        "\n",
        "  classifier = xgb.XGBClassifier(global_parms)\n",
        "  rs_model = HyperbandSearchCV(classifier,\n",
        "                               param_distributions = params,\n",
        "                               n_jobs = -1,\n",
        "                               verbose = 3,\n",
        "                               random_state = random_state,\n",
        "                               max_iter = 220,\n",
        "                               cv = 5,\n",
        "                               scoring = 'neg_log_loss'\n",
        "                                )\n",
        "  rs_model.fit(X_train,y_train)\n",
        "  return rs_model.cv_results_['mean_test_score'], rs_model.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUhVFBwFOlAZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "def run_xgb(params, dtrain, dtest):\n",
        "  param_all = global_parms.copy()\n",
        "  param_all.update(params)\n",
        "  watchlist = [(dtest,'eval'), (dtrain,'train')]\n",
        "  evals_result = {}\n",
        "  xgb_model = xgb.train(param_all, \n",
        "                      dtrain, \n",
        "                      num_boost_round=100,\n",
        "                      evals=watchlist,\n",
        "                      evals_result=evals_result,\n",
        "                      verbose_eval = False)\n",
        "  y_pred = xgb_model.predict(dtest)\n",
        "\n",
        "  return evals_result['eval']['logloss'][-1], accuracy_score(y_test, np.round(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "7nljVOtmLxvP",
        "outputId": "ba6b8a2f-22b0-4ce2-a550-d38ec6a0d9bf"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-65086941f9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrand_run_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_run_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m      \u001b[0mtuned_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune_xgb_hb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m      \u001b[0mloss_minimum_accumulate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtuned_xgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mdf_tune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_minimum_accumulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-8abc90730ef2>\u001b[0m in \u001b[0;36mtune_xgb_hb\u001b[0;34m(params, X_train, y_train, random_state)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                 )\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mrs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-bb899395deb4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mParameters\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0ms_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_iter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() takes from 2 to 3 positional arguments but 4 were given"
          ]
        }
      ],
      "source": [
        "rand_run_list = [0, 100, 200, 300, 400]\n",
        "for i, random_state in enumerate(rand_run_list):\n",
        "     tuned_xgb = tune_xgb_hb(tune_params, X_train, y_train,random_state = random_state)\n",
        "     loss_minimum_accumulate = np.minimum.accumulate(-1.0 *tuned_xgb[0])\n",
        "     df_tune = pd.DataFrame(loss_minimum_accumulate).transpose()\n",
        "     df_tune.to_csv(\"HB_tune_xgb_2.csv\", mode = 'a', index = False, header = False)\n",
        "     eval_result = run_xgb(tuned_xgb[1], dtrain, dtest)\n",
        "     df_test = pd.DataFrame(eval_result).transpose()\n",
        "     df_test.to_csv(\"HB_test_xgb_2.csv\", mode = 'a', index = False, header = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nasHPcuXrjsZ"
      },
      "outputs": [],
      "source": [
        "df_tune = pd.DataFrame(loss_minimum_accumulate).transpose()\n",
        "df_tune.to_csv(\"Hyperband_tune_xgb_2.csv\", mode = 'a', index = False, header = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOf6zJaFrr21"
      },
      "outputs": [],
      "source": [
        "eval_result = run_xgb(tuned_xgb[1], dtrain, dtest)\n",
        "df_test = pd.DataFrame(eval_result).transpose()\n",
        "df_test.to_csv(\"Hyperband_test_xgb_2.csv\", mode = 'a', index = False, header = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Hyperband-tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}